clear
clc
rng('default');


directory = 'D:\checkout\elec4712-elec4713-thesis\final model files\version 1 backprop\data\abridging2014\nodirection\compression data';
X = csvread([directory filesep 'Abridging2014CompressionInputs.csv']); % input set
Y = csvread([directory filesep 'Abridging2014CompressionTargets.csv']); % target set
Xmean = csvread([directory filesep 'Abridging2014CompressionInputsMeans.csv']); % input set (means)
Ymean = csvread([directory filesep 'Abridging2014CompressionTargetsMeans.csv']); % target set (means)


% hyperparameter optimisation
optimVars = [
    optimizableVariable('NetworkDepth', [0 2], 'Type', 'integer') % test 1: [1 5], test 2: [0 2], test 3: [0 2]
    optimizableVariable('HiddenSize', [1 6], 'Type', 'integer') % test 1: [1 20], test 2: [1 6], test 3: [1 6]
    optimizableVariable('InitialLearnRate', [1e-2 0.4], 'Transform','log') % test 1: [1e-3 0.4], test 2: [1e-3 0.4], test 3: [1e-2, 0.4]
    optimizableVariable('Momentum', [0.6 0.95]) % test 1: [0.5 0.99], test 2: [0.8 0.99], test 3: [0.6 0.95] 
    % note: poslin = relu
    % optimizableVariable('ActivationFunction', {'logsig', 'tansig',
    % 'poslin'}, 'Type', 'categorical') % used in test 1 (all hidden)
    optimizableVariable('HiddenActivation1', {'logsig', 'tansig', 'poslin'}, 'Type', 'categorical') % used in test 2 & 3
    optimizableVariable('HiddenActivation2', {'logsig', 'tansig', 'poslin'}, 'Type', 'categorical') % used in test 2 & 3
    optimizableVariable('OutputActivation', {'logsig', 'tansig', 'poslin'}, 'Type', 'categorical') % used in test 2 & 3
    % optimizableVariable('TrainingFunction', {'traingd', 'traingdm', 'traingdx', 'trainrp', 'trainbr'}, 'Type', 'categorical') % test 1: ['traingd', 'traingdm', 'traingdx', 'trainrp', 'trainbr'], test 2: ['traingd', 'traingdm', 'trainbr'], test 3: just traingdm (comment out and set in objective function)
    % optimizableVariable('LossFunction', {'mse', 'sse', 'crossentropy'}, 'Type', 'categorical')]; % test 1: [mse, sse, crossentropy], test 2: sse, test 3: mse
optimResult = ffObjFcn(X, Y); 
BayesObjectTest2 = bayesopt(optimResult, optimVars, ...
    'MaxObj', 1000, ...
    'IsObjectiveDeterministic', false, ...
    'PlotFcn', {@plotMinObjective, @plotElapsedTime}); 



% % cross-validation w/ final network
% Y_part = cvpartition(Y, 'KFold', 5); 
% for i = 1:Y_part.NumTestSets
%     % train, validate, test?
%     disp(['Fold ', num2str(i)])
% %     testClasses = Y(Y_part.test(i));
% %     testClasses
%     trIdx = Y_part.training(i);
%     testIdx = Y_part.test(i); 
%     trainCnt = sum(trIdx == 1);
%     testCnt = sum(testIdx == 1);
%     disp('Train:test ratio: ')
%     trainCnt/(trainCnt + testCnt)
%     
% %     disp('Training input');
%     XTrain = X(trIdx, :);
% %     disp('Testing input');
%     XTest = X(testIdx, :);
% %     disp('Training target');
%     YTrain = Y(trIdx);
% %     disp('Testing target'); 
%     YTest = Y(testIdx);
%     
%     valIdx = randperm(numel(YTrain), ceil(0.2*numel(YTrain))); 
%     XValidation = XTrain(valIdx, :);
%     XTrain(valIdx, :) = [];
%     YValidation = YTrain(valIdx); 
%     YTrain(valIdx, :) = []; 
%     
% end 

% mse = crossval('mse',X,Y,'Predfun',traingdm); 

function optimResult = ffObjFcn(X, Y)
optimResult = @valErrorFun;
    function [valError, cons, fileName] = valErrorFun(optVars)
        if optVars.NetworkDepth == 0
            net = fitnet([]); 
        else 
            hiddenLayers = optVars.HiddenSize.*ones(1,optVars.NetworkDepth);
            net = fitnet(hiddenLayers);
            for i = 1:optVars.NetworkDepth
                net.layers{i}.transferFcn = char(optVars.ActivationFunction); % for test 1
                if i == 1
                    net.layers{1}.transferFcn = char(optVars.HiddenActivation1);
                elseif i ==2 
                    net.layers{2}.transferFcn = char(optVars.HiddenActivation2); 
                end 
            end 
        end 
        net.layers{optVars.NetworkDepth + 1}.transferFcn = char(optVars.OutputActivation); % for tests 2 and 3
        
        % net.trainFcn = char(optVars.TrainingFunction); % for tests 1 & 2
        net.trainFcn = 'traingdm'; % for test 3

        net.trainParam.lr = optVars.InitialLearnRate;
        net.trainParam.time = 20; 
        if (strcmp(net.trainFcn, 'traingdm') || strcmp(net.TrainFcn, 'traingdx'))
            net.trainParam.mc = optVars.Momentum;
        end 
        % net.performFcn = char(optVars.LossFunction); % for test 1
        % net.performFcn = 'sse'; % for test 2
        net.performFcn = 'mse'; % for test 3
        
        [trainedNet, tr] = train(net, X', Y', 'useGPU', 'yes'); % NOTE: by default, feedforwardnets partition data 0.7:0.15:0.15 according to dividerand function
%         y = net(X'); 
%         perf = perform(net,y,X')
%         disp(tr)
        valError = tr.best_vperf;
        fileName = num2str(valError) + ".mat";
        dirFile = 'D:\checkout\elec4712-elec4713-thesis\final model files\version 1 backprop\matlab\backpropOptim\test3\' + fileName; 
        save(dirFile, 'trainedNet', 'valError', 'net'); 
        cons = []; 
        
    end
end




function testval = train_net (XTRAIN, YTRAIN, XTEST, YTEST)

    net = feedforwardnet(10);
    [net, tr] = train(net, XTRAIN', YTRAIN');
    plotperform(tr); 
    
    % all of the below is for classification tasks 
    yNet = net(XTEST');
    %'// find which output (of the three dummy variables) has the highest probability
    [~,classNet] = max(yNet',[],2);

    %// convert YTEST into a format that can be compared with classNet
    [~,classTest] = find(YTEST);


    %'// Check the success of the classifier
    cp = classperf(classTest, classNet);
    testval = cp.CorrectRate; %// replace this with your preferred metric
    
end 